name: ğŸ›¡ï¸ Vulnerability Assessment & CVE Analysis

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master ]
  schedule:
    # Daily vulnerability scans at 3 AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      full_scan:
        description: 'Perform full vulnerability scan'
        required: false
        default: 'false'
        type: boolean

permissions:
  contents: read
  security-events: write
  actions: write
  issues: write

jobs:
  snyk-vulnerability-scan:
    name: ğŸ Snyk Vulnerability Scanning
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: ğŸ” Run Snyk to check for vulnerabilities
      uses: snyk/actions/node@master
      continue-on-error: true
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      with:
        args: --severity-threshold=high --json-file-output=snyk-results.json
    
    - name: ğŸ“Š Upload Snyk results to GitHub Code Scanning
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: snyk.sarif
    
    - name: ğŸ“¤ Upload Snyk JSON results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: snyk-vulnerability-report
        path: snyk-results.json
        retention-days: 30

  dependency-check:
    name: ğŸ” OWASP Dependency Check
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4
    
    - name: â˜• Set up JDK 11
      uses: actions/setup-java@v4
      with:
        java-version: '11'
        distribution: 'temurin'
    
    - name: ğŸ” Run OWASP Dependency Check
      uses: dependency-check/Dependency-Check_Action@main
      with:
        project: 'Cybersecurity-Framework'
        path: '.'
        format: 'ALL'
        args: >
          --enableRetired
          --enableExperimental
          --nvdApiKey ${{ secrets.NVD_API_KEY }}
          --nvdApiDelay 2000
          --cveValidForHours 24
    
    - name: ğŸ“Š Upload Dependency Check results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: dependency-check-report
        path: reports/
        retention-days: 30

  nist-cve-analysis:
    name: ğŸ›ï¸ NIST CVE Database Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4
    
    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'
    
    - name: ğŸ“¦ Install CVE analysis dependencies
      run: |
        pip install requests beautifulsoup4 python-nvd3 cvss pandas
    
    - name: ğŸ” Run NIST CVE Analysis
      env:
        NVD_API_KEY: ${{ secrets.NVD_API_KEY }}
      run: |
        python3 << 'EOF'
        import requests
        import json
        import os
        from datetime import datetime, timedelta
        
        def fetch_recent_cves():
            """Fetch recent CVEs from NIST NVD API"""
            api_key = os.environ.get('NVD_API_KEY')
            
            # Get CVEs from last 7 days
            end_date = datetime.now()
            start_date = end_date - timedelta(days=7)
            
            url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
            headers = {"apiKey": api_key} if api_key else {}
            
            params = {
                "pubStartDate": start_date.strftime("%Y-%m-%dT%H:%M:%S.000"),
                "pubEndDate": end_date.strftime("%Y-%m-%dT%H:%M:%S.000"),
                "resultsPerPage": 100
            }
            
            try:
                response = requests.get(url, headers=headers, params=params, timeout=30)
                response.raise_for_status()
                return response.json()
            except Exception as e:
                print(f"Error fetching CVEs: {e}")
                return {"vulnerabilities": []}
        
        def analyze_cves(cve_data):
            """Analyze CVE data for security insights"""
            analysis = {
                "total_cves": len(cve_data.get("vulnerabilities", [])),
                "high_severity": 0,
                "critical_severity": 0,
                "categories": {},
                "recent_trends": []
            }
            
            for vuln in cve_data.get("vulnerabilities", []):
                cve = vuln.get("cve", {})
                metrics = cve.get("metrics", {})
                
                # Analyze CVSS scores
                if "cvssMetricV31" in metrics:
                    score = metrics["cvssMetricV31"][0]["cvssData"]["baseScore"]
                    if score >= 9.0:
                        analysis["critical_severity"] += 1
                    elif score >= 7.0:
                        analysis["high_severity"] += 1
                
                # Categorize by CWE
                weaknesses = cve.get("weaknesses", [])
                for weakness in weaknesses:
                    for desc in weakness.get("description", []):
                        cwe = desc.get("value", "Unknown")
                        analysis["categories"][cwe] = analysis["categories"].get(cwe, 0) + 1
            
            return analysis
        
        # Main execution
        print("ğŸ” Fetching recent CVEs from NIST NVD...")
        cve_data = fetch_recent_cves()
        
        print("ğŸ“Š Analyzing CVE data...")
        analysis = analyze_cves(cve_data)
        
        # Generate report
        report = {
            "scan_date": datetime.now().isoformat(),
            "analysis": analysis,
            "raw_data": cve_data
        }
        
        with open("nist-cve-analysis.json", "w") as f:
            json.dump(report, f, indent=2)
        
        print(f"ğŸ“‹ Analysis Complete:")
        print(f"  Total CVEs (last 7 days): {analysis['total_cves']}")
        print(f"  Critical Severity: {analysis['critical_severity']}")
        print(f"  High Severity: {analysis['high_severity']}")
        print(f"  Top CWE Categories: {list(analysis['categories'].keys())[:5]}")
        
        EOF
    
    - name: ğŸ“Š Upload NIST CVE Analysis
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: nist-cve-analysis
        path: nist-cve-analysis.json
        retention-days: 30

  trivy-container-scan:
    name: ğŸ³ Trivy Container Vulnerability Scan
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4
    
    - name: ğŸ” Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        severity: 'CRITICAL,HIGH,MEDIUM'
    
    - name: ğŸ“Š Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'
    
    - name: ğŸ“¤ Upload Trivy results artifact
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: trivy-vulnerability-report
        path: trivy-results.sarif
        retention-days: 30

  vulnerability-risk-assessment:
    name: ğŸ“Š Vulnerability Risk Assessment
    runs-on: ubuntu-latest
    needs: [snyk-vulnerability-scan, dependency-check, nist-cve-analysis, trivy-container-scan]
    if: always()
    timeout-minutes: 15
    
    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4
    
    - name: ğŸ“¥ Download all vulnerability reports
      uses: actions/download-artifact@v4
      with:
        path: vulnerability-reports/
    
    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'
    
    - name: ğŸ“¦ Install analysis dependencies
      run: |
        pip install pandas matplotlib seaborn
    
    - name: ğŸ“Š Generate Risk Assessment Report
      run: |
        python3 << 'EOF'
        import json
        import os
        import pandas as pd
        from datetime import datetime
        
        def load_vulnerability_data():
            """Load vulnerability data from all scans"""
            data = {
                "snyk": [],
                "dependency_check": [],
                "nist_cve": [],
                "trivy": []
            }
            
            # Process available reports
            reports_dir = "vulnerability-reports"
            if os.path.exists(reports_dir):
                for root, dirs, files in os.walk(reports_dir):
                    for file in files:
                        if file.endswith('.json'):
                            try:
                                with open(os.path.join(root, file), 'r') as f:
                                    content = json.load(f)
                                    # Process based on file name/content
                                    if 'snyk' in file.lower():
                                        data["snyk"].append(content)
                                    elif 'nist' in file.lower():
                                        data["nist_cve"].append(content)
                            except Exception as e:
                                print(f"Error processing {file}: {e}")
            
            return data
        
        def calculate_risk_score(vulnerabilities):
            """Calculate overall risk score"""
            if not vulnerabilities:
                return 0
            
            risk_weights = {
                "critical": 10,
                "high": 7,
                "medium": 4,
                "low": 1
            }
            
            total_score = 0
            total_vulns = 0
            
            for scan_type, vulns in vulnerabilities.items():
                for vuln_set in vulns:
                    if isinstance(vuln_set, dict):
                        # Process vulnerability data based on structure
                        if 'analysis' in vuln_set:
                            analysis = vuln_set['analysis']
                            total_score += analysis.get('critical_severity', 0) * risk_weights['critical']
                            total_score += analysis.get('high_severity', 0) * risk_weights['high']
                            total_vulns += analysis.get('total_cves', 0)
            
            return min(total_score / max(total_vulns, 1) * 10, 100)
        
        def generate_recommendations(risk_score):
            """Generate security recommendations based on risk assessment"""
            recommendations = []
            
            if risk_score >= 80:
                recommendations.extend([
                    "ğŸš¨ CRITICAL: Immediate attention required",
                    "ğŸ“¦ Update all dependencies to latest secure versions",
                    "ğŸ”’ Implement emergency security patches",
                    "ğŸ›¡ï¸ Enable additional security monitoring"
                ])
            elif risk_score >= 60:
                recommendations.extend([
                    "âš ï¸ HIGH: Schedule security updates within 48 hours",
                    "ğŸ“¦ Update high-risk dependencies",
                    "ğŸ” Increase vulnerability scan frequency"
                ])
            elif risk_score >= 40:
                recommendations.extend([
                    "ğŸ“‹ MEDIUM: Plan security updates for next maintenance window",
                    "ğŸ“Š Review and prioritize vulnerability fixes"
                ])
            else:
                recommendations.extend([
                    "âœ… LOW: Maintain current security posture",
                    "ğŸ“… Continue regular vulnerability assessments"
                ])
            
            return recommendations
        
        # Main execution
        print("ğŸ“Š Loading vulnerability data...")
        vuln_data = load_vulnerability_data()
        
        print("ğŸ§® Calculating risk score...")
        risk_score = calculate_risk_score(vuln_data)
        
        print("ğŸ“‹ Generating recommendations...")
        recommendations = generate_recommendations(risk_score)
        
        # Generate comprehensive report
        report = {
            "assessment_date": datetime.now().isoformat(),
            "overall_risk_score": round(risk_score, 2),
            "risk_level": "CRITICAL" if risk_score >= 80 else "HIGH" if risk_score >= 60 else "MEDIUM" if risk_score >= 40 else "LOW",
            "scan_summary": {
                "snyk_scans": len(vuln_data["snyk"]),
                "dependency_checks": len(vuln_data["dependency_check"]),
                "nist_cve_analyses": len(vuln_data["nist_cve"]),
                "trivy_scans": len(vuln_data["trivy"])
            },
            "recommendations": recommendations,
            "next_assessment": "24 hours"
        }
        
        with open("vulnerability-risk-assessment.json", "w") as f:
            json.dump(report, f, indent=2)
        
        # Generate markdown report
        with open("vulnerability-assessment-report.md", "w") as f:
            f.write("# ğŸ›¡ï¸ Vulnerability Risk Assessment Report\n\n")
            f.write(f"**Assessment Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}\n")
            f.write(f"**Repository:** ${{ github.repository }}\n\n")
            f.write(f"## ğŸ“Š Overall Risk Score: {report['overall_risk_score']}/100 ({report['risk_level']})\n\n")
            f.write("## ğŸ” Scan Summary\n")
            for scan_type, count in report["scan_summary"].items():
                f.write(f"- {scan_type.replace('_', ' ').title()}: {count} scans completed\n")
            f.write("\n## ğŸ’¡ Recommendations\n")
            for rec in recommendations:
                f.write(f"- {rec}\n")
            f.write(f"\n**Next Assessment:** {report['next_assessment']}\n")
        
        print(f"âœ… Risk Assessment Complete:")
        print(f"  Overall Risk Score: {report['overall_risk_score']}/100")
        print(f"  Risk Level: {report['risk_level']}")
        print(f"  Recommendations: {len(recommendations)}")
        
        EOF
    
    - name: ğŸ“¤ Upload Risk Assessment Report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: vulnerability-risk-assessment
        path: |
          vulnerability-risk-assessment.json
          vulnerability-assessment-report.md
        retention-days: 30

  vulnerability-alerting:
    name: ğŸš¨ Vulnerability Alerting
    runs-on: ubuntu-latest
    needs: [vulnerability-risk-assessment]
    if: always()
    
    steps:
    - name: ğŸ“¥ Download risk assessment
      uses: actions/download-artifact@v4
      with:
        name: vulnerability-risk-assessment
        path: ./
    
    - name: ğŸš¨ High Risk Alert
      if: needs.vulnerability-risk-assessment.result == 'success'
      run: |
        if [ -f vulnerability-risk-assessment.json ]; then
          RISK_SCORE=$(cat vulnerability-risk-assessment.json | python3 -c "import sys, json; print(json.load(sys.stdin)['overall_risk_score'])")
          RISK_LEVEL=$(cat vulnerability-risk-assessment.json | python3 -c "import sys, json; print(json.load(sys.stdin)['risk_level'])")
          
          if (( $(echo "$RISK_SCORE >= 60" | bc -l) )); then
            echo "ğŸš¨ HIGH RISK DETECTED: Score $RISK_SCORE ($RISK_LEVEL)"
            
            # Create GitHub issue for high-risk vulnerabilities
            curl -X POST \
              -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              -H "Accept: application/vnd.github.v3+json" \
              https://api.github.com/repos/${{ github.repository }}/issues \
              -d "{
                \"title\": \"ğŸš¨ High Risk Vulnerabilities Detected - Score: $RISK_SCORE\",
                \"body\": \"**Risk Level:** $RISK_LEVEL\n**Risk Score:** $RISK_SCORE/100\n\n**Action Required:** Please review the vulnerability assessment report and implement recommended security updates.\n\n**Scan Date:** $(date)\n\n[View Assessment Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\",
                \"labels\": [\"security\", \"vulnerability\", \"high-priority\"]
              }"
          fi
        fi